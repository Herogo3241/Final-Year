{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "7b9fffed",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Libraries imported successfully.\n"
     ]
    }
   ],
   "source": [
    "# Cell 1: Install & Imports\n",
    "# Install any missing libraries if needed (run in terminal: pip install stable-baselines3 xgboost pandas numpy gymnasium)\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import json\n",
    "import zipfile\n",
    "import os\n",
    "from stable_baselines3 import DQN\n",
    "from sklearn.multioutput import MultiOutputRegressor\n",
    "import xgboost as xgb\n",
    "import gymnasium as gym\n",
    "from gymnasium import spaces\n",
    "\n",
    "print(\"Libraries imported successfully.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "febc233e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trained DQN agent loaded successfully from zip.\n",
      "World model loaded successfully from pickle.\n"
     ]
    }
   ],
   "source": [
    "# Cell 2: Load Trained Artifacts (DQN Agent + World Model)\n",
    "import joblib\n",
    "\n",
    "model_path = 'dqn_mimic_patient_model_v1.zip'\n",
    "world_model_path = 'world_model.pkl'\n",
    "\n",
    "# Load the trained DQN agent\n",
    "try:\n",
    "    dqn_model = DQN.load(model_path)\n",
    "    print(\"Trained DQN agent loaded successfully from zip.\")\n",
    "except FileNotFoundError:\n",
    "    print(f\"Error: File '{model_path}' not found. Ensure the zip file exists in the current directory.\")\n",
    "    raise\n",
    "except Exception as e:\n",
    "    print(f\"Error loading model: {e}\")\n",
    "    raise\n",
    "\n",
    "# Load the world model separately\n",
    "try:\n",
    "    world_model = joblib.load(world_model_path)\n",
    "    print(\"World model loaded successfully from pickle.\")\n",
    "except FileNotFoundError:\n",
    "    print(f\"Error: File '{world_model_path}' not found. Ensure the pickle exists in the current directory.\")\n",
    "    world_model = None\n",
    "except Exception as e:\n",
    "    print(f\"Error loading world model: {e}\")\n",
    "    world_model = None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "0a478b46",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Synthetic patient JSON loaded.\n",
      "Bundle type: transaction\n",
      "Number of entries: 943\n"
     ]
    }
   ],
   "source": [
    "# Cell 3: Load Synthetic Patient JSON (Synthea)\n",
    "# Load the FHIR Bundle JSON\n",
    "json_file_path = 'output/fhir/Bethel526_Gerlach374_49578d6f-b690-6615-598e-3ee3719d1c69.json'\n",
    "with open(json_file_path, 'r') as f:\n",
    "    synthea_data = json.load(f)\n",
    "\n",
    "print(\"Synthetic patient JSON loaded.\")\n",
    "print(f\"Bundle type: {synthea_data.get('type')}\")\n",
    "print(f\"Number of entries: {len(synthea_data.get('entry', []))}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "3e8d9483",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Inspecting FHIR Bundle structure...\n",
      "Entry 0: Resource Type = Patient\n",
      "  - Name: Bethel526 Gerlach374\n",
      "Entry 1: Resource Type = Encounter\n",
      "Entry 2: Resource Type = MedicationRequest\n",
      "Entry 3: Resource Type = Claim\n",
      "Entry 4: Resource Type = ExplanationOfBenefit\n",
      "\n",
      "Unique resource types: {'Encounter', 'Immunization', 'Provenance', 'Condition', 'MedicationAdministration', 'SupplyDelivery', 'MedicationRequest', 'Device', 'CarePlan', 'Observation', 'DocumentReference', 'Procedure', 'ExplanationOfBenefit', 'ImagingStudy', 'CareTeam', 'DiagnosticReport', 'Patient', 'AllergyIntolerance', 'Claim', 'Medication'}\n"
     ]
    }
   ],
   "source": [
    "# Cell 4: Inspect Synthea Structure & Quick Validation\n",
    "print(\"Inspecting FHIR Bundle structure...\")\n",
    "for i, entry in enumerate(synthea_data['entry'][:5]):  # Show first 5 entries\n",
    "    resource = entry.get('resource', {})\n",
    "    resource_type = resource.get('resourceType')\n",
    "    print(f\"Entry {i}: Resource Type = {resource_type}\")\n",
    "    if resource_type == 'Observation':\n",
    "        print(f\"  - Code: {resource.get('code', {}).get('coding', [{}])[0].get('code')}\")\n",
    "        print(f\"  - Value: {resource.get('valueQuantity', {}).get('value')}\")\n",
    "    elif resource_type == 'Patient':\n",
    "        name_obj = resource.get('name', [{}])[0]\n",
    "        given_names = \" \".join(name_obj.get('given', []))\n",
    "        family_name = name_obj.get('family', '')\n",
    "        print(f\"  - Name: {given_names} {family_name}\")\n",
    "\n",
    "# Validation: Check for key resource types\n",
    "resource_types = [entry['resource'].get('resourceType') for entry in synthea_data['entry']]\n",
    "print(f\"\\nUnique resource types: {set(resource_types)}\")\n",
    "if 'Observation' not in resource_types:\n",
    "    print(\"Warning: No Observations found in JSON. Model features may be missing.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "1d74e173",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracted patient features:\n",
      "  heart_rate: 85.0\n",
      "  systolic_bp: Missing (will impute to 0)\n",
      "  diastolic_bp: Missing (will impute to 0)\n",
      "  temperature: 37.841\n",
      "  lactate: Missing (will impute to 0)\n",
      "Mapping complete. Patient features ready.\n"
     ]
    }
   ],
   "source": [
    "# Cell 5: Map Synthea Fields â†’ Model Features (States & Actions)\n",
    "# Define mappings from FHIR codes to model features\n",
    "# FHIR uses LOINC codes for observations. Map common ones to your model's state columns.\n",
    "# Note: Synthea may use specific codes; adjust based on your JSON. Actions are not in JSON (they're outputs), so skip.\n",
    "fhir_to_state_map = {\n",
    "    '8867-4': 'heart_rate',      # LOINC for Heart rate\n",
    "    '8480-6': 'systolic_bp',     # Systolic blood pressure\n",
    "    '8462-4': 'diastolic_bp',    # Diastolic blood pressure\n",
    "    '8310-5': 'temperature',     # Body temperature\n",
    "    '5902-2': 'lactate'          # Lactate (may not be present in Synthea)\n",
    "}\n",
    "\n",
    "# Extract observations into a dict\n",
    "patient_features = {}\n",
    "for entry in synthea_data['entry']:\n",
    "    resource = entry['resource']\n",
    "    if resource.get('resourceType') == 'Observation':\n",
    "        code = resource.get('code', {}).get('coding', [{}])[0].get('code')\n",
    "        value = resource.get('valueQuantity', {}).get('value')\n",
    "        if code in fhir_to_state_map and value is not None:\n",
    "            patient_features[fhir_to_state_map[code]] = float(value)\n",
    "\n",
    "# Check extracted features\n",
    "state_cols = ['heart_rate', 'systolic_bp', 'diastolic_bp', 'temperature', 'lactate']\n",
    "print(\"Extracted patient features:\")\n",
    "for col in state_cols:\n",
    "    if col in patient_features:\n",
    "        print(f\"  {col}: {patient_features[col]}\")\n",
    "    else:\n",
    "        print(f\"  {col}: Missing (will impute to 0)\")\n",
    "\n",
    "# Impute missing features with 0 (as in training)\n",
    "for col in state_cols:\n",
    "    if col not in patient_features:\n",
    "        patient_features[col] = 0.0\n",
    "\n",
    "print(\"Mapping complete. Patient features ready.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "3578c705",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initial state vector: [85.     0.     0.    37.841  0.   ]\n"
     ]
    }
   ],
   "source": [
    "# Cell 6: Preprocess / Build Time-Bucketed Features or Single Initial State\n",
    "# For testing, we use a single initial state (not time-bucketed, as the model simulates sequentially).\n",
    "# Convert to numpy array for the env.\n",
    "initial_state = np.array([patient_features[col] for col in state_cols], dtype=np.float32)\n",
    "print(f\"Initial state vector: {initial_state}\")\n",
    "\n",
    "# Optional: If you want to simulate multiple time steps, you could create a sequence, but for now, start with one.\n",
    "# Note: The model expects states in the same units as training (e.g., HR in bpm, BP in mmHg, Temp in C, Lactate in mmol/L).\n",
    "# If Synthea uses different units, convert here (e.g., if Temp is in F, convert to C)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "25f38d4e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Unit checks and imputation complete.\n"
     ]
    }
   ],
   "source": [
    "# Cell 7: Impute Missing Features / Scaling / Unit Checks\n",
    "# Already handled imputation in Cell 5. Add unit checks/scaling if needed.\n",
    "# Example: Ensure Temp is in Celsius (Synthea often uses F; convert if necessary).\n",
    "if 'temperature' in patient_features and patient_features['temperature'] > 50:  # Likely F\n",
    "    patient_features['temperature'] = (patient_features['temperature'] - 32) * 5/9\n",
    "    initial_state[3] = patient_features['temperature']  # Update array\n",
    "    print(\"Temperature converted from F to C.\")\n",
    "\n",
    "# Scaling: If your training data was scaled, apply the same scaler here (e.g., StandardScaler).\n",
    "# For simplicity, assume no scaling in training; if yes, load and apply.\n",
    "print(\"Unit checks and imputation complete.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "85395a41",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initial states DataFrame:\n",
      "   heart_rate  systolic_bp  diastolic_bp  temperature  lactate\n",
      "0        85.0          0.0           0.0       37.841      0.0\n",
      "Test environment created with synthetic patient initial state.\n"
     ]
    }
   ],
   "source": [
    "# Cell 8: Create Initial State Matrix for the Simulator\n",
    "# The env expects a DataFrame-like initial_states for reset. Create a dummy DF with this state.\n",
    "initial_states_df = pd.DataFrame([initial_state], columns=state_cols)\n",
    "print(f\"Initial states DataFrame:\\n{initial_states_df}\")\n",
    "\n",
    "# Recreate the env with this initial state (modify PatientSimulatorEnv to accept custom initial).\n",
    "# For testing, we'll override the reset to use our state.\n",
    "class TestPatientSimulatorEnv(gym.Env):\n",
    "    def __init__(self, world_model, custom_initial_state, state_cols, action_cols):\n",
    "        super().__init__()\n",
    "        self.world_model = world_model\n",
    "        self.custom_initial_state = custom_initial_state\n",
    "        self.state_cols = state_cols\n",
    "        self.action_cols = action_cols\n",
    "        self.action_space = spaces.Discrete(25)\n",
    "        self.observation_space = spaces.Box(low=-np.inf, high=np.inf, shape=(len(state_cols),), dtype=np.float32)\n",
    "        self.current_state = None\n",
    "        self.episode_length = 0\n",
    "    \n",
    "    def reset(self, seed=None, options=None):\n",
    "        self.current_state = self.custom_initial_state.copy()\n",
    "        self.episode_length = 0\n",
    "        return self.current_state, {}\n",
    "    \n",
    "    def step(self, action):\n",
    "        # Same as original, but use custom initial\n",
    "        action_vector = np.zeros(len(self.action_cols))  # Placeholder; map action to dosages if needed\n",
    "        model_input = np.concatenate([self.current_state, action_vector]).reshape(1, -1)\n",
    "        predicted_next_state = self.world_model.predict(model_input)[0]\n",
    "        previous_lactate = self.current_state[self.state_cols.index('lactate')]\n",
    "        self.current_state = predicted_next_state\n",
    "        self.episode_length += 1\n",
    "        new_lactate = self.current_state[self.state_cols.index('lactate')]\n",
    "        reward = (previous_lactate - new_lactate) * 10\n",
    "        terminated = new_lactate > 4.0 or (new_lactate < 1.0 and self.episode_length > 5) or self.episode_length >= 50\n",
    "        if terminated and new_lactate > 4.0:\n",
    "            reward -= 100\n",
    "        elif terminated and new_lactate < 1.0:\n",
    "            reward += 50\n",
    "        return self.current_state, reward, terminated, False, {}\n",
    "\n",
    "test_env = TestPatientSimulatorEnv(world_model, initial_state, state_cols, ['norepinephrine', 'fluid_bolus'])\n",
    "print(\"Test environment created with synthetic patient initial state.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "1117c4db",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sample prediction (no action): Current state [85.     0.     0.    37.841  0.   ] -> Next state [8.1925209e+01 1.4667047e+02 8.5988884e+01 1.0246951e+02 2.9216770e-02]\n",
      "Input shape: (1, 7), Output shape: (5,)\n",
      "Ranges: States 0.0-85.0, Predicted 0.029216770082712173-146.67047119140625\n"
     ]
    }
   ],
   "source": [
    "# Cell 9: Sanity-Check World Model Predictions on Sample Inputs\n",
    "# Test the world model with the initial state + sample actions.\n",
    "sample_action = np.array([0.0, 0.0])  # No meds\n",
    "sample_input = np.concatenate([initial_state, sample_action]).reshape(1, -1)\n",
    "predicted_next = world_model.predict(sample_input)[0]\n",
    "print(f\"Sample prediction (no action): Current state {initial_state} -> Next state {predicted_next}\")\n",
    "\n",
    "# Check shapes and ranges\n",
    "print(f\"Input shape: {sample_input.shape}, Output shape: {predicted_next.shape}\")\n",
    "print(f\"Ranges: States {np.min(initial_state)}-{np.max(initial_state)}, Predicted {np.min(predicted_next)}-{np.max(predicted_next)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "5cd5515b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Episode 1: Length 50, Total Reward -10.591890335083008\n",
      "Episode 2: Length 50, Total Reward -10.591890335083008\n",
      "Episode 3: Length 50, Total Reward -10.591890335083008\n",
      "Episode 4: Length 50, Total Reward -10.591890335083008\n",
      "Episode 5: Length 50, Total Reward -10.591890335083008\n",
      "Testing complete.\n"
     ]
    }
   ],
   "source": [
    "# Cell 10: Run the DQN Agent in PatientSimulatorEnv with Synthetic Patient\n",
    "# Test the DQN agent in the test env.\n",
    "episodes = 5  # Test with a few episodes\n",
    "trajectories = []\n",
    "\n",
    "for ep in range(episodes):\n",
    "    obs, info = test_env.reset()\n",
    "    done = False\n",
    "    ep_trajectory = {'states': [obs], 'actions': [], 'rewards': []}\n",
    "    while not done:\n",
    "        action, _ = dqn_model.predict(obs, deterministic=True)\n",
    "        obs, reward, done, truncated, info = test_env.step(action)\n",
    "        ep_trajectory['states'].append(obs)\n",
    "        ep_trajectory['actions'].append(action)\n",
    "        ep_trajectory['rewards'].append(reward)\n",
    "    trajectories.append(ep_trajectory)\n",
    "    print(f\"Episode {ep+1}: Length {len(ep_trajectory['states'])-1}, Total Reward {sum(ep_trajectory['rewards'])}\")\n",
    "\n",
    "print(\"Testing complete.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "2402fc01",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average reward: -10.591890335083008\n",
      "Average lactate change: 1.0591890811920166\n",
      "Outputs saved to test_trajectories.json.\n"
     ]
    }
   ],
   "source": [
    "# Cell 11: Record Trajectories, Metrics and Save Outputs\n",
    "# Convert NumPy arrays to lists for JSON serialization\n",
    "def convert_trajectory(traj):\n",
    "    return {\n",
    "        'states': [state.tolist() if hasattr(state, 'tolist') else state for state in traj['states']],\n",
    "        'actions': [int(a) for a in traj['actions']],\n",
    "        'rewards': [float(r) for r in traj['rewards']]\n",
    "    }\n",
    "\n",
    "trajectories_serializable = [convert_trajectory(traj) for traj in trajectories]\n",
    "\n",
    "# Save trajectories to a JSON file.\n",
    "with open('test_trajectories.json', 'w') as f:\n",
    "    json.dump(trajectories_serializable, f, indent=4)\n",
    "\n",
    "# Compute metrics (e.g., average reward, lactate changes).\n",
    "avg_reward = np.mean([sum(traj['rewards']) for traj in trajectories])\n",
    "lactate_changes = [traj['states'][-1][4] - traj['states'][0][4] for traj in trajectories]  # Lactate index 4\n",
    "print(f\"Average reward: {avg_reward}\")\n",
    "print(f\"Average lactate change: {np.mean(lactate_changes)}\")\n",
    "\n",
    "print(\"Outputs saved to test_trajectories.json.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "edc4ebb7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initial state shape: (5,)\n",
      "World model input shape: (1, 7)\n",
      "Predicted output shape: (5,)\n",
      "State ranges: 0.0 - 85.0\n",
      "Mapped features: {'heart_rate': 85.0, 'temperature': 37.841, 'systolic_bp': 0.0, 'diastolic_bp': 0.0, 'lactate': 0.0}\n",
      "Warning: Missing/imputed features: ['systolic_bp', 'diastolic_bp', 'lactate']\n",
      "Debugging complete.\n"
     ]
    }
   ],
   "source": [
    "# Cell 12: Debugging / Validation Utilities (Column Checks, Shapes, Ranges)\n",
    "# Utility functions for debugging.\n",
    "def check_shapes():\n",
    "    print(f\"Initial state shape: {initial_state.shape}\")\n",
    "    print(f\"World model input shape: {sample_input.shape}\")\n",
    "    print(f\"Predicted output shape: {predicted_next.shape}\")\n",
    "\n",
    "def check_ranges(df=None):\n",
    "    if df is not None:\n",
    "        print(f\"DataFrame ranges:\\n{df.describe()}\")\n",
    "    print(f\"State ranges: {np.min(initial_state)} - {np.max(initial_state)}\")\n",
    "\n",
    "def validate_fhir_mapping():\n",
    "    print(\"Mapped features:\", patient_features)\n",
    "    missing = [col for col in state_cols if patient_features.get(col, 0) == 0]\n",
    "    if missing:\n",
    "        print(f\"Warning: Missing/imputed features: {missing}\")\n",
    "\n",
    "check_shapes()\n",
    "check_ranges()\n",
    "validate_fhir_mapping()\n",
    "print(\"Debugging complete.\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "mimic_rl",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
